{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Pandas for data handling\n",
    "import pandas # https://pandas.pydata.org/\n",
    "# from pandas.plotting import scatter_matrix\n",
    "\n",
    "# pretty tables\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy for numerical computing\n",
    "import numpy # https://numpy.org/\n",
    "\n",
    "# MatPlotLib+Seaborn for visualization\n",
    "import matplotlib.pyplot as pl  # https://matplotlib.org/\n",
    "import seaborn as sns\n",
    "\n",
    "# assessment\n",
    "from sklearn import model_selection # for model comparisons\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# data preprocessing / feature selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# combining\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file ...\n",
      "Removing rows with missing data ...\n",
      "Reading list of problem variables X and y...\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print('Loading data from file ...')  \n",
    "dataset = pandas.read_csv('winequality-white.csv')\n",
    "print('Removing rows with missing data ...')  \n",
    "dataset = dataset.dropna()\n",
    "print('Reading list of problem variables X and y...')\n",
    "X_name = [ 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol' ] \n",
    "y_name = 'quality'\n",
    "X = dataset[X_name]   \n",
    "y = dataset[y_name]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning data into parts: formative (for development) and summative (for testing) ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting the seed allows for repeatability\n",
    "seed = 5 \n",
    "\n",
    "print('Partitioning data into parts: formative (for development) and summative (for testing) ...')\n",
    "test_size = 0.20   # means 20 percent\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of algorithms to train ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chose the Algorithms\n",
    "\n",
    "seed = 42 # setting the seed allows for repeatability\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(50,), # one hidden layer with 50 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(50), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'logistic',  # ReLU is the default option\n",
    "                    # activation = {'identity','logistic','tanh','relu'}  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    # solver={'lbfgs','sgd','adam'}  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(50,60), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "\n",
    "print('Reading list of algorithms to train ...')\n",
    "models = []\n",
    "models.append(( 'relu_MLP_hidden-layer(50)', mlp1 ))\n",
    "models.append(( 'logistic_MLP_hidden-layer(50)', mlp2 ))\n",
    "models.append(( 'relu_MLP_hidden-layer(50,60)', mlp3 ))\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ++ NOW WORKING ON ALGORITHM relu_MLP_hidden-layer(50) ++\n",
      "Iteration 1, loss = 14.07085299\n",
      "Iteration 2, loss = 1.55507896\n",
      "Iteration 3, loss = 1.34487144\n",
      "Iteration 4, loss = 1.31187600\n",
      "Iteration 5, loss = 1.30618500\n",
      "Iteration 6, loss = 1.30358940\n",
      "Iteration 7, loss = 1.30210391\n",
      "Iteration 8, loss = 1.30134136\n",
      "Iteration 9, loss = 1.30084004\n",
      "Iteration 10, loss = 1.30069790\n",
      "Training set score: 0.443594\n",
      " ++ NOW WORKING ON ALGORITHM logistic_MLP_hidden-layer(50) ++\n",
      "Iteration 1, loss = 1.52649482\n",
      "Iteration 2, loss = 1.34100473\n",
      "Iteration 3, loss = 1.31572096\n",
      "Iteration 4, loss = 1.32434303\n",
      "Iteration 5, loss = 1.35156698\n",
      "Iteration 6, loss = 1.33249435\n",
      "Iteration 7, loss = 1.32191958\n",
      "Iteration 8, loss = 1.33927079\n",
      "Iteration 9, loss = 1.34767041\n",
      "Iteration 10, loss = 1.38084202\n",
      "Training set score: 0.298111\n",
      " ++ NOW WORKING ON ALGORITHM relu_MLP_hidden-layer(50,60) ++\n",
      "Iteration 1, loss = 8.89549420\n",
      "Iteration 2, loss = 1.37955823\n",
      "Iteration 3, loss = 1.29772836\n",
      "Iteration 4, loss = 1.28415097\n",
      "Iteration 5, loss = 1.26633062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.25998813\n",
      "Iteration 7, loss = 1.25757507\n",
      "Iteration 8, loss = 1.24956329\n",
      "Iteration 9, loss = 1.29216297\n",
      "Iteration 10, loss = 1.26315874\n",
      "Training set score: 0.454569\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "# NOTE: this example won't converge because our max_iter choice is too few epochs \n",
    "# (otherwise it will take too long for a live demo), \n",
    "# so we catch the warning and ignore it here\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    \n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" ++ NOW WORKING ON ALGORITHM %s ++\" % name)  \n",
    "    selected_model = model\n",
    "    selected_model.fit(X_train, y_train)\n",
    "    print(\"Training set score: %f\" % selected_model.score(X_train, y_train))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " clasification report on relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 14.07085299\n",
      "Iteration 2, loss = 1.55507896\n",
      "Iteration 3, loss = 1.34487144\n",
      "Iteration 4, loss = 1.31187600\n",
      "Iteration 5, loss = 1.30618500\n",
      "Iteration 6, loss = 1.30358940\n",
      "Iteration 7, loss = 1.30210391\n",
      "Iteration 8, loss = 1.30134136\n",
      "Iteration 9, loss = 1.30084004\n",
      "Iteration 10, loss = 1.30069790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00       289\n",
      "           6       0.47      1.00      0.64       460\n",
      "           7       0.00      0.00      0.00       168\n",
      "           8       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.47       980\n",
      "   macro avg       0.08      0.17      0.11       980\n",
      "weighted avg       0.22      0.47      0.30       980\n",
      "\n",
      " clasification report on logistic_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 1.52649482\n",
      "Iteration 2, loss = 1.34100473\n",
      "Iteration 3, loss = 1.31572096\n",
      "Iteration 4, loss = 1.32434303\n",
      "Iteration 5, loss = 1.35156698\n",
      "Iteration 6, loss = 1.33249435\n",
      "Iteration 7, loss = 1.32191958\n",
      "Iteration 8, loss = 1.33927079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.34767041\n",
      "Iteration 10, loss = 1.38084202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.29      1.00      0.46       289\n",
      "           6       0.00      0.00      0.00       460\n",
      "           7       0.00      0.00      0.00       168\n",
      "           8       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.29       980\n",
      "   macro avg       0.05      0.17      0.08       980\n",
      "weighted avg       0.09      0.29      0.13       980\n",
      "\n",
      " clasification report on relu_MLP_hidden-layer(50,60) \n",
      "Iteration 1, loss = 8.89549420\n",
      "Iteration 2, loss = 1.37955823\n",
      "Iteration 3, loss = 1.29772836\n",
      "Iteration 4, loss = 1.28415097\n",
      "Iteration 5, loss = 1.26633062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.25998813\n",
      "Iteration 7, loss = 1.25757507\n",
      "Iteration 8, loss = 1.24956329\n",
      "Iteration 9, loss = 1.29216297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 10, loss = 1.26315874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.43      0.21      0.28       289\n",
      "           6       0.47      0.87      0.61       460\n",
      "           7       0.00      0.00      0.00       168\n",
      "           8       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.47       980\n",
      "   macro avg       0.15      0.18      0.15       980\n",
      "weighted avg       0.35      0.47      0.37       980\n",
      "\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" clasification report on %s \" % name) \n",
    "    selected_model = model\n",
    "    selected_model.fit(X_train, y_train)\n",
    "    y_predicted = selected_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_predicted))  # compare predictions with ground truth\n",
    "print('Done')\n",
    "\n",
    "# y_predicted = mlp.predict(X_test)   # use the trained classifier to predict on the test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of algorithms to train ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chose the Algorithms\n",
    "\n",
    "seed = 42 # setting the seed allows for repeatability\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(50,), # one hidden layer with 50 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(50), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # activation = {'identity','logistic','tanh','relu'}  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    # solver={'lbfgs','sgd','adam'}  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=50,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(50), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.01 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "\n",
    "print('Reading list of algorithms to train ...')\n",
    "models = []\n",
    "models.append(( 'sgd-solver_relu_MLP_hidden-layer(50)', mlp1 ))\n",
    "models.append(( '50-iter-epoch_relu_MLP_hidden-layer(50)', mlp2 ))\n",
    "models.append(( '0.01-learning-rate_relu_MLP_hidden-layer(50)', mlp3 ))\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sgd-solver_relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 5.06014007\n",
      "Iteration 2, loss = 2.10351281\n",
      "Iteration 3, loss = 2.16555570\n",
      "Iteration 4, loss = 2.16858144\n",
      "Iteration 5, loss = 2.16705411\n",
      "Iteration 6, loss = 2.16544330\n",
      "Iteration 7, loss = 2.16461398\n",
      "Iteration 8, loss = 2.16386446\n",
      "Iteration 9, loss = 2.16329669\n",
      "Iteration 10, loss = 2.16326857\n",
      "Training set score: 0.443594\n",
      " 50-iter-epoch_relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 14.07085299\n",
      "Iteration 2, loss = 1.55507896\n",
      "Iteration 3, loss = 1.34487144\n",
      "Iteration 4, loss = 1.31187600\n",
      "Iteration 5, loss = 1.30618500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.30358940\n",
      "Iteration 7, loss = 1.30210391\n",
      "Iteration 8, loss = 1.30134136\n",
      "Iteration 9, loss = 1.30084004\n",
      "Iteration 10, loss = 1.30069790\n",
      "Iteration 11, loss = 1.30068136\n",
      "Iteration 12, loss = 1.30117097\n",
      "Iteration 13, loss = 1.30056102\n",
      "Iteration 14, loss = 1.30023016\n",
      "Iteration 15, loss = 1.30017349\n",
      "Iteration 16, loss = 1.30109968\n",
      "Iteration 17, loss = 1.30082135\n",
      "Iteration 18, loss = 1.30111085\n",
      "Iteration 19, loss = 1.30070001\n",
      "Iteration 20, loss = 1.30001552\n",
      "Iteration 21, loss = 1.30100383\n",
      "Iteration 22, loss = 1.30062363\n",
      "Iteration 23, loss = 1.30204229\n",
      "Iteration 24, loss = 1.30058687\n",
      "Iteration 25, loss = 1.30085163\n",
      "Iteration 26, loss = 1.30134970\n",
      "Iteration 27, loss = 1.30204623\n",
      "Iteration 28, loss = 1.30051690\n",
      "Iteration 29, loss = 1.30014349\n",
      "Iteration 30, loss = 1.30043647\n",
      "Iteration 31, loss = 1.30055471\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.443594\n",
      " 0.01-learning-rate_relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 5.70458553\n",
      "Iteration 2, loss = 2.26326823\n",
      "Iteration 3, loss = 1.39896561\n",
      "Iteration 4, loss = 1.28529254\n",
      "Iteration 5, loss = 1.23656826\n",
      "Iteration 6, loss = 1.29189014\n",
      "Iteration 7, loss = 1.27364522\n",
      "Iteration 8, loss = 1.20518439\n",
      "Iteration 9, loss = 1.23260890\n",
      "Iteration 10, loss = 1.23341917\n",
      "Training set score: 0.489535\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "# NOTE: this example won't converge because our max_iter choice is too few epochs \n",
    "# (otherwise it will take too long for a live demo), \n",
    "# so we catch the warning and ignore it here\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    \n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" %s \" % name)  \n",
    "    selected_model = model\n",
    "    selected_model.fit(X_train, y_train)\n",
    "    print(\"Training set score: %f\" % selected_model.score(X_train, y_train))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of algorithms to train ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chose the Algorithms\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(50,), # one hidden layer with 50 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(50), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'logistic',  # ReLU is the default option\n",
    "                    # activation = {'identity','logistic','tanh','relu'}  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    # solver={'lbfgs','sgd','adam'}  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(50,60), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(50,), # one hidden layer with 50 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp5 = MLPClassifier(hidden_layer_sizes=(50), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # activation = {'identity','logistic','tanh','relu'}  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    # solver={'lbfgs','sgd','adam'}  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.1 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=50,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "mlp6 = MLPClassifier(hidden_layer_sizes=(50), # two hidden layer with 50 and 60 neurons\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=1e-4,  # regulariztion parameter, set to default=0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.01 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=10,  # number of epochs, default=200\n",
    "                    random_state=42,\n",
    "                    verbose=10, \n",
    "                    )\n",
    "\n",
    "print('Reading list of algorithms to train ...')\n",
    "models = []\n",
    "models.append(( 'relu_MLP_hidden-layer(50)', mlp1 ))\n",
    "models.append(( 'logistic_MLP_hidden-layer(50)', mlp2 ))\n",
    "models.append(( 'relu_MLP_hidden-layer(50,60)', mlp3 ))\n",
    "models.append(( 'sgd-solver_relu_MLP_hidden-layer(50)', mlp4 ))\n",
    "models.append(( '50-iter-epoch_relu_MLP_hidden-layer(50)', mlp2 ))\n",
    "models.append(( '0.01-learning-rate_relu_MLP_hidden-layer(50)', mlp3 ))\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 14.07085299\n",
      "Iteration 2, loss = 1.55507896\n",
      "Iteration 3, loss = 1.34487144\n",
      "Iteration 4, loss = 1.31187600\n",
      "Iteration 5, loss = 1.30618500\n",
      "Iteration 6, loss = 1.30358940\n",
      "Iteration 7, loss = 1.30210391\n",
      "Iteration 8, loss = 1.30134136\n",
      "Iteration 9, loss = 1.30084004\n",
      "Iteration 10, loss = 1.30069790\n",
      "Training set score: 0.443594\n",
      " logistic_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 1.52649482\n",
      "Iteration 2, loss = 1.34100473\n",
      "Iteration 3, loss = 1.31572096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.32434303\n",
      "Iteration 5, loss = 1.35156698\n",
      "Iteration 6, loss = 1.33249435\n",
      "Iteration 7, loss = 1.32191958\n",
      "Iteration 8, loss = 1.33927079\n",
      "Iteration 9, loss = 1.34767041\n",
      "Iteration 10, loss = 1.38084202\n",
      "Training set score: 0.298111\n",
      " relu_MLP_hidden-layer(50,60) \n",
      "Iteration 1, loss = 8.89549420\n",
      "Iteration 2, loss = 1.37955823\n",
      "Iteration 3, loss = 1.29772836\n",
      "Iteration 4, loss = 1.28415097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.26633062\n",
      "Iteration 6, loss = 1.25998813\n",
      "Iteration 7, loss = 1.25757507\n",
      "Iteration 8, loss = 1.24956329\n",
      "Iteration 9, loss = 1.29216297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.26315874\n",
      "Training set score: 0.454569\n",
      " sgd-solver_relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 5.06014007\n",
      "Iteration 2, loss = 2.10351281\n",
      "Iteration 3, loss = 2.16555570\n",
      "Iteration 4, loss = 2.16858144\n",
      "Iteration 5, loss = 2.16705411\n",
      "Iteration 6, loss = 2.16544330\n",
      "Iteration 7, loss = 2.16461398\n",
      "Iteration 8, loss = 2.16386446\n",
      "Iteration 9, loss = 2.16329669\n",
      "Iteration 10, loss = 2.16326857\n",
      "Training set score: 0.443594\n",
      " 50-iter-epoch_relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 1.52649482\n",
      "Iteration 2, loss = 1.34100473\n",
      "Iteration 3, loss = 1.31572096\n",
      "Iteration 4, loss = 1.32434303\n",
      "Iteration 5, loss = 1.35156698\n",
      "Iteration 6, loss = 1.33249435\n",
      "Iteration 7, loss = 1.32191958\n",
      "Iteration 8, loss = 1.33927079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.34767041\n",
      "Iteration 10, loss = 1.38084202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.298111\n",
      " 0.01-learning-rate_relu_MLP_hidden-layer(50) \n",
      "Iteration 1, loss = 8.89549420\n",
      "Iteration 2, loss = 1.37955823\n",
      "Iteration 3, loss = 1.29772836\n",
      "Iteration 4, loss = 1.28415097\n",
      "Iteration 5, loss = 1.26633062\n",
      "Iteration 6, loss = 1.25998813\n",
      "Iteration 7, loss = 1.25757507\n",
      "Iteration 8, loss = 1.24956329\n",
      "Iteration 9, loss = 1.29216297\n",
      "Iteration 10, loss = 1.26315874\n",
      "Training set score: 0.454569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "# NOTE: this example won't converge because our max_iter choice is too few epochs \n",
    "# (otherwise it will take too long for a live demo), \n",
    "# so we catch the warning and ignore it here\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    \n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" %s \" % name)  \n",
    "    selected_model = model\n",
    "    selected_model.fit(X_train, y_train)\n",
    "    print(\"Training set score: %f\" % selected_model.score(X_train, y_train))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparison shows the following:\n",
    "For both 'relu' and 'logistic' activation function, training score has no change\n",
    "Adding one more hidden layer showed slight improvement\n",
    "increasing number of linear unit/neurons did not show any improvement\n",
    "changing the solver did not not show improvement\n",
    "increasing the iteration number (epoch) did not show improvement and converged\n",
    "reducing the learning-rate showed  some slight improvement in accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: KNeighborsClassifier() \n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.16      0.09      0.11        34\n",
      "           5       0.47      0.53      0.50       289\n",
      "           6       0.53      0.57      0.55       460\n",
      "           7       0.41      0.35      0.38       168\n",
      "           8       0.29      0.08      0.12        25\n",
      "\n",
      "    accuracy                           0.49       980\n",
      "   macro avg       0.31      0.27      0.28       980\n",
      "weighted avg       0.47      0.49      0.48       980\n",
      "\n",
      "Training set score: 0.651608\n",
      "done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhoss\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "selected_model = KNeighborsClassifier()\n",
    "selected_model.fit(X_train, y_train)\n",
    "predictions = selected_model.predict(X_test)\n",
    "\n",
    "print(\"Algorithm: %s \" % selected_model)\n",
    "print('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
    "print(\"Training set score: %f\" % selected_model.score(X_train, y_train))      \n",
    "print('done \\n')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "KNN algorithm has been used as a non-neural network classfier.\n",
    "The accuracy on higher than the neural network model observed in this homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
